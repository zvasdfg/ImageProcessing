{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Input,UpSampling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar dimensión al tensor y normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels  = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciar red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convNN = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadir capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convNN.add(Conv2D(filters     =32, \n",
    "                  kernel_size =(3, 3), \n",
    "                  activation  ='relu', \n",
    "                  input_shape =(28, 28, 1)))\n",
    "\n",
    "convNN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "convNN.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "convNN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "convNN.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "convNN.add(Flatten())\n",
    "convNN.add(Dense(units=64, activation='relu'))\n",
    "convNN.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "convNN.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 42s 693us/step - loss: 0.1387 - accuracy: 0.9564\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 39s 657us/step - loss: 0.0424 - accuracy: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e487b32808>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convNN.fit(train_images,train_labels,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 184us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = convNN.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9884999990463257\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:' ,test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "new_input = Input(shape=(640, 480, 3))\n",
    "model = VGG16(include_top=False, input_tensor=new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 640, 480, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 640, 480, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 640, 480, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 320, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 320, 240, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 320, 240, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 160, 120, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 160, 120, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 160, 120, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 160, 120, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 80, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 80, 60, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 80, 60, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 80, 60, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 40, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 40, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 40, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 40, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 20, 15, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))  \n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2D(8, (3, 3), activation='relu', padding='same',name = \"entry_encoded\")(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "entry_encoded (Conv2D)       (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  \n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute '_get_distribution_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3b6b3754a0be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Images\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Images\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mcallback_metrics\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     callbacks.set_params({\n\u001b[0;32m    121\u001b[0m         \u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Images\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Images\\lib\\site-packages\\keras\\callbacks\\tensorboard_v2.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;34m\"\"\"Sets Keras model and writes graph if specified.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Images\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[1;31m# possibly distributed settings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m     self._log_write_dir = distributed_file_utils.write_dirpath(\n\u001b[1;32m-> 1532\u001b[1;33m         self.log_dir, self.model._get_distribution_strategy())  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   1533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute '_get_distribution_strategy'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = autoencoder.layers[0]\n",
    "encoder = Model(input_img,encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_input = Input(shape=(4,4,8,))\n",
    "deco = autoencoder.layers[-7](decoded_input)\n",
    "deco = autoencoder.layers[-6](deco)\n",
    "deco = autoencoder.layers[-5](deco)\n",
    "deco = autoencoder.layers[-4](deco)\n",
    "deco = autoencoder.layers[-3](deco)\n",
    "deco = autoencoder.layers[-2](deco)\n",
    "deco = autoencoder.layers[-1](deco)\n",
    "decoder = Model(decoded_input,deco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 4, 4, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodes = encoder.predict(x_test)\n",
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "decodes = decoder.predict(encodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e49091a788>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "plt.imshow(decodes[2,:,:,0],cmap= 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e490cda148>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0][:,:,0],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
